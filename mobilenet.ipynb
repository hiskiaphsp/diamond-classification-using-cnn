{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f21f395-b329-4feb-838f-385583fc6c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34131 images belonging to 8 classes.\n",
      "Epoch 1/10\n",
      "1067/1067 [==============================] - 1601s 1s/step - loss: 0.0722 - accuracy: 0.9796 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1067/1067 [==============================] - 1207s 1s/step - loss: 0.0356 - accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1067/1067 [==============================] - 1241s 1s/step - loss: 0.0311 - accuracy: 0.9921 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1067/1067 [==============================] - 1224s 1s/step - loss: 0.0308 - accuracy: 0.9919 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1067/1067 [==============================] - 1274s 1s/step - loss: 0.0283 - accuracy: 0.9926 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1067/1067 [==============================] - 1143s 1s/step - loss: 0.0248 - accuracy: 0.9938 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1067/1067 [==============================] - 1118s 1s/step - loss: 0.0264 - accuracy: 0.9933 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1067/1067 [==============================] - 1138s 1s/step - loss: 0.0232 - accuracy: 0.9943 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1067/1067 [==============================] - 1248s 1s/step - loss: 0.0229 - accuracy: 0.9941 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1067/1067 [==============================] - 1263s 1s/step - loss: 0.0231 - accuracy: 0.9942 - lr: 0.0010\n",
      "Model saved to mobilenetv2_model.h5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ImageDataGenerator.flow_from_directory() got an unexpected keyword argument 'steps_per_epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     83\u001b[0m datagen_test \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m---> 84\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     91\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: ImageDataGenerator.flow_from_directory() got an unexpected keyword argument 'steps_per_epoch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Path ke direktori dataset Anda\n",
    "dataset_path = 'dataset/web_scraped/'\n",
    "train_dir = 'dataset/training/'\n",
    "test_dir = 'dataset/testing/'\n",
    "\n",
    "# Set your input shape and the number of classes\n",
    "input_shape = (224, 224, 3)  # Adjust according to your image size\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "\n",
    "# Use pre-trained MobileNetV2 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build your model using the MobileNetV2 base\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data Augmentation\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load training data with augmentation\n",
    "batch_size = 32  # Adjust as needed\n",
    "train_data = datagen_train.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(input_shape[0], input_shape[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Learning rate scheduler function\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 30:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 20:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 10:\n",
    "        lr *= 1e-2\n",
    "    return lr\n",
    "\n",
    "# Learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Fit the model\n",
    "epochs = 10  # Adjust as needed\n",
    "model.fit(train_data, epochs=epochs, steps_per_epoch=len(train_data), callbacks=[lr_scheduler])\n",
    "\n",
    "# Save the model to a file\n",
    "model_save_path = 'mobilenetv2_model.h5'\n",
    "model.save(model_save_path)\n",
    "print(f'Model saved to {model_save_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
